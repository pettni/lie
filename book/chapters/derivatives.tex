% !TEX root = ../root.tex

\chapter{Derivatives}

\begin{itemize_outcomes}
  \item Definition of derivatives on manifolds.
  \item Differentiation rules.
\end{itemize_outcomes}

\todo[inline]{Define derivatives w.r.t. matrix elements only, motivate that we can disregard parameterized expressions.}

\begin{definition}
  The \textbf{right derivative} of $f : \M \rightarrow \N$ at $\X \in {\cM}$ is a linear mapping $\mathrm{d}^r f_\X : T {\M}_{\X} \rightarrow T \N_{f(\X)}$ such that:
  \begin{equation}
    \label{eq:deriv_rght}
    \mathrm{d}^r f_\X \coloneq \lim_{\a \rightarrow 0} \frac{f( \X \oplus_r\a) \ominus_r f(\X)}{\a} = \lim_{\a\ \rightarrow 0} \frac{\log \left( f(\X)^{-1} \circ  f(\X \circ \exp(\a) \right)}{\a},
  \end{equation}
  where $\a \in T_\X \check{\M}$ is a member of the parameterized Lie algebra and the division is component-wise.

  Similarly, the \textbf{left derivative} is a linear mapping $\mathrm{d}^r f_\X : T {\M}_{e} \rightarrow T \N_{e}$ such that
  \begin{equation}
    \label{eq:deriv_left}
    \mathrm{d}^l f_\X \coloneq \lim_{\a \rightarrow 0} \frac{f( \X \oplus_l \a) \ominus_l  f(\X)}{\a} = \lim_{\a\ \rightarrow 0} \frac{\log \left( f(\exp(\a) \circ \X) \circ f(\X)^{-1} \right)}{\a},
  \end{equation}
\end{definition}

From the definition it can be seen that for small $\a$ it approximately holds that
\begin{equation}
  \label{eq:right_approx}
  f(\X \oplus_r {\a}) = f(\X) \oplus_r \left( \mathrm{d}^r f_\X \a + \mathcal O(\| \a \|^2) \right),
\end{equation}
and for left-plus:
\begin{equation}
  \label{eq:left_approx}
  f(\a \oplus_l \X) = \left( \mathrm{d}^l f_\X \a + \mathcal O(\| \a \|^2) \right) \oplus_l f(\X).
\end{equation}
From \eqref{eq:right_approx} and \eqref{eq:left_approx} we have that for small $\a$,
\begin{equation}
  f(\X) \oplus_r (\mathrm{d}^r f_\X  \a) \overset{\eqref{eq:right_approx}}= f(\X \oplus_r \a) \overset{\eqref{eq:plus_adjoint}}= f\left( \bAd_\X \a \oplus_l \X\right)  \overset{\eqref{eq:left_approx}}= ( \mathrm{d}^l f_\X \bAd_\X \a) \oplus_l f(\X).
\end{equation}
Consequently,
\begin{equation}
  \exp( \mathrm{d}^l f_\X \bAd_\X \a ) = f(\X) \circ \exp (\mathrm{d}^r f_\X \a) \circ f(\X)^{-1} = \bAd_{f(\X)} \exp (\mathrm{d}^r f_\X \a),
\end{equation}
and due to \eqref{eq:exp_adj_comm} it follows that left and right derivatives are related through the adjoints via
\begin{equation}
  \label{eq:derivative_trans}
  \mathrm{d}^l f_\X = \bAd_{f(\X)} \; \mathrm{d}^r f_\X \; \bAd_{\X}^{-1}.
\end{equation}
With the interpretation of the adjoints as coordinate changes this formula can be seen as follows: the derivative of $f$ with respect to a tangent vector $^\id\a$ at $\id$ can be obtained by
\begin{enumerate}
  \item Convert $^{\id}\a$ to a tangent vector at $\X$: $^{\X}\a = \bAd_\X^{-1}  {^\id\a} \in T_\X \cM$,
  \item Map the tangent vector through the derivative: ${^\X}\b = \mathrm{d}^r f_\X \; {^\X\a} \in T_{f(\X)} \cM$,
  \item Convert the result back to a tangent vector at $\id$: ${^\id}\b = \bAd_{f(\X)}  {^\X\b} \in T_\id \cM$.
\end{enumerate}

Jacobians on Lie Groups satisfy the chain rule. Indeed, if $f(\X) = g \circ h (\X)$ for some $g : \M' \rightarrow \M''$ and $h : \M \rightarrow \M'$ we have with $\Z \coloneq h(\X)$
\begin{equation}
  \label{eq:chain_rule}
  \begin{aligned}
    \mathrm{d}^r (g \circ h)_\X = \lim_{\a \rightarrow 0} \frac{g \left( h( \X \oplus_r \a ) \right) \ominus_r g(h(\X))}{\a}  \overset{\eqref{eq:right_approx}} = \lim_{\a \rightarrow 0} \frac{g \left( h( \X ) \oplus_r \left( \mathrm{d}^r h_\X \a + \mathcal O(\|\a\|^2) \right)  \right) \ominus_r g(h(\X))}{\a} \\
    \overset{\eqref{eq:right_approx}} = \lim_{\a \rightarrow 0} \frac{ \left( g (\Z) \oplus_r \left( \mathrm{d}^r g_\Z \;  \mathrm{d}^r h_\X \a + \mathcal O(\| \a \|^2) \right) \right) \ominus_r g(h(\X))}{\a} \overset{\eqref{eq:x_plus_a_minus_x}}= \mathrm{d}^r g_\Z \;  \mathrm{d}^r h_\X.
  \end{aligned}
\end{equation}
An analogous left chain rule can be developed in the same manner via \eqref{eq:left_approx} in lieu of \eqref{eq:right_approx}.

\begin{properties}[title=Important formulas for Lie group derivatives]
  \begin{itemize}
    \item Right derivative: $\mathrm{d}^r f_\X \coloneq \lim_{\a\ \rightarrow 0} \frac{\log \left( f(\X)^{-1} \circ  f(\X \circ \exp(\a) \right)}{\a} \in T_\X \M$,
    \item Left derivative: $\mathrm{d}^l f_\X \coloneq \lim_{\a\ \rightarrow 0} \frac{\log \left( f(\exp(\a) \circ \X) \circ  f(\X)^{-1} \right)}{\a} \in T_\id \M$,
    \item Conversion between left and right jacobians: $\mathrm{d}^l f_\X = \bAd_{f(\X)} \; \mathrm{d}^r f_\X \; \bAd_{\X}^{-1}$,
    \item Right chain rule: $\mathrm{d}^r (g (h(\X)))_\X =  \mathrm{d}^r g_{h(\X)} \;  \mathrm{d}^r h_\X$,
    \item Left chain rule: $\mathrm{d}^l (g (h(\X)))_\X =  \mathrm{d}^l g_{h(\X)} \;  \mathrm{d}^l h_\X$.
  \end{itemize}
\end{properties}

\section{Global Derivative}

For a mapping $f : \M \rightarrow \N$ between two manifolds the classical way to define a derivative $\mathbf{D} f_\X$ is as a mapping $T_\X \M \rightarrow T_{f(\X)} \N$ defined as
\begin{equation}
  \mathrm{D} f_\X \B \coloneq \left. \frac{\mathrm{d}}{\mathrm{d}t} \right|_{t = 0} f(\gamma(t)), \qquad \begin{cases}
    \gamma(0) = \X, \\
    \gamma'(0) = \B.
  \end{cases}
\end{equation}
for $\B \in T_\X \M$. Note that this definition wouldn't make sense for an arbitrary matrix $\B$; for $\gamma$ to take values in $\M$ the derivative at zero must be on the form $\B = \X \hat \a$. Being in global matrix coordinates, $\mathrm{D} f_\X \B$ typically does not exhibit the structure of the tangent space at $T_{f(\X)} \N$. However, it can be mapped to the tangent space via group action, which yields an alternative way of defining the right and left derivatives.

\begin{equation}
  \label{eq:rght_deriv_traditional}
  \begin{aligned}
    \mathrm{d}^r f_\X \a & \coloneq \left( f(\X)^{-1} \left( \mathrm{D} f_\X \; \X \hat \a \right) \right)^{\vee} = \left( f(\X)^{-1} \left( \left. \frac{\mathrm{d}}{\mathrm{d}t} \right|_{t = 0} f(\gamma(t)) \right) \right)^\vee, \qquad \begin{cases} \gamma(0) = \X, \\ \gamma'(0) = \X \hat \a, \end{cases}  \\
    \mathrm{d}^l f_\X \a & \coloneq \left( \left( \mathrm{D} f_\X \; \hat \a \X \right) f(\X)^{-1} \right)^{\vee} = \left( \left( \left. \frac{\mathrm{d}}{\mathrm{d}t} \right|_{t = 0} f(\gamma(t)) \right) f(\X)^{-1}  \right)^\vee, \qquad \begin{cases} \gamma(0) = \X, \\ \gamma'(0) = \hat \a \X. \end{cases}
  \end{aligned}
\end{equation}

\todo[inline]{Show that these definitions agree with those above}

\section{Product rule}

Consider a function $f(\X) = g(\X) \circ h(\X)$, we utilize \eqref{eq:right_approx} to obtain
\begin{equation}
  \begin{aligned}
    f(\X \oplus \a) & = \left( g (\X) \oplus \left(\mathrm{d}^r g_\X \a + \mathcal O(\a^2) \right) \right) \circ  \left( h (\X) \oplus \left( \mathrm{d}^r h_\X  \a + \mathcal O(\a^2) \right) \right)
    \\
                    & = g(\X) \circ \exp( \mathrm{d}^r g_\X \a + \mathcal O(\a^2)) \circ h(\X) \circ \exp( \mathrm{d}^r h_\X \a + \mathcal O(\a^2))
    \\
                    & = g(\X) \circ h(\X) \circ \left( \Ad_{h(\X)^{-1}} \exp \left( \mathrm{d}^r g_\X \a + \mathcal O(\a^2) \right)  \right) \circ \exp( \mathrm{d}^r h_\X \a+ \mathcal O(\a^2) )
    \\
                    & \overset{\eqref{eq:exp_adj_comm}}=  g(\X) \circ h(\X) \circ \left( \exp \bAd_{h(\X)^{-1}} \left( \mathrm{d}^r g_\X \a + \mathcal O(\a^2) \right)\right) \circ \exp( \mathrm{d}^r h_\X \a + \mathcal O(\a^2))
    \\
                    & \overset{\eqref{eq:bch_formula}}=  g(\X) \circ h(\X) \circ \exp \left( \bAd_{h(\X)^{-1}} \mathrm{d}^r g_\X \a + \mathrm{d}^r h_\X \a + \mathcal O(\a^2)) \right).
  \end{aligned}
\end{equation}
From here we can conclude that
\begin{equation}
  \label{eq:product_rule}
  \mathrm{d}^r (g \circ h)_\X = \bAd_{h(\X)^{-1}} \mathrm{d}^r g_\X + \mathrm{d}^r h_\X
\end{equation}
which is the product rule for Lie group derivatives.

\begin{remark}
  \label{remark:total_derivative}
  There is no Lie group equivalent of the rule of total derivative. Consider
  \begin{equation}
    \begin{aligned}
      f(g(\X \oplus \a), h(\X \oplus \a))
       & \approx f \left( g(\X) \oplus \mathrm{d}^r g_\X \; \a , h(\X) \oplus \mathrm{d}^r h_\X \; \a \right)                                                                                      \\
       & \approx f \left( g(\X) , h(\X) \oplus \mathrm{d} h_\X \a \right) \oplus \mathrm{d}^r f_{g} \; \mathrm{d}^r g_\X \a                                                                        \\
       & \approx \left[ f \left( g(\X) , h(\X) \right) \oplus \mathrm{d}^r f_h \; \mathrm{d}^r h_\X \a \right] \oplus \mathrm{d}^r f_{g} \; \mathrm{d}^r g_\X \a                                   \\
       & =  f \left( g(\X) , h(\X) \right) \circ \left[ \exp\left( \mathrm{d}^r f_h \; \mathrm{d}^r h_\X \a  \right) \circ \exp\left ( \mathrm{d}^r f_{g} \; \mathrm{d}^r g_\X \a \right) \right].
    \end{aligned}
  \end{equation}
  That is, if $f(\X) = f(g(\X), h(\X))$ we typically have that
  \begin{equation}
    \mathrm{d}^r (f(g(\X), h(\X)))_\X  \neq  \mathrm{d}^r f_{g(\X)} \; \mathrm {d}^r g_\X + \mathrm{d}^r f_{h(\X)} \; \mathrm {d}^r h_\X.
  \end{equation}
  However, from \eqref{eq:bch_formula} it can be seen that if
  \begin{equation}
    \left[ \mathrm{d}^r f_{h(\X)} \; \mathrm{d}^r h_\X \a  ,   \mathrm{d}^r f_{g(\X)} \; \mathrm{d}^r g_\X \a  \right] = 0, \qquad \forall \a,
  \end{equation}
  then the rule of total derivatives applies. One important case when this holds is when $f$ takes values in $\mathbb{E}(n)$ since matrix multiplication on $\mathbb{E}(n)$ corresponds to vector addition on $\mathbb{R}^n$ and hence all brackets are zero.
\end{remark}

\section{Lie Bracket as the Derivative of the Adjoint}

The Lie bracket between two tangent elements can be defined as the global derivative of the adjoint operator at identity. Consider the mapping $f(\X) \coloneq \bAd_\X \b = \X \hat \b \X^{-1}$ and take a curve $\gamma(t) \in \M$ such that $\gamma(0) = \X$ and $\gamma'(0) = \hat \a$. From $\frac{\mathrm{d}}{\mathrm{d}t} \gamma(t) \gamma(t)^{-1} = 0$ it follows that $\frac{\mathrm{d}}{\mathrm{d}t} \gamma(t)^{-1} = - \gamma(t)^{-1} \gamma'(t) \gamma(t)^{-1}$, hence
\begin{equation}
  \left. \frac{\mathrm{d}}{\mathrm{d}t} \right|_{t=0} f(\gamma(t))  = \gamma'(0) \hat \b \gamma(0)^{-1} - \gamma(0) \hat \b \gamma(0)^{-1} \gamma'(0) \gamma(0)^{-1} = \hat \a \hat \b \X^{-1} - \X \hat \b \X^{-1} \hat \a \X^{-1} .
\end{equation}
\begin{properties}
  The derivatives of $\bAd_\X$ with respect to $\X$ are
  \begin{subequations}
    \begin{align}
      \label{eq:bAd_D}
      \mathrm{D} (\bAd_\X \b)_\X \hat \a & = \hat \a \hat \b \X^{-1} - \X \hat \b \X^{-1} \hat \a X^{-1},                                                                                   \\
      \label{eq:bAd_dr}
      \mathrm{d}^r (\bAd_\X \b)_\X \a    & = \left( \mathrm{D} \left(\bAd_\X \b \right)_\X \X \hat \a \right)^\vee = \bAd_\X \left[ \a, \b \right] = \left[ \bAd_\X \a, \bAd_\X \b \right], \\
      \label{eq:bAd_dl}
      \mathrm{d}^l (\bAd_\X \b)_\X \a    & = \left( \mathrm{D} \left(\bAd_\X \b \right)_\X \hat \a \X \right)^\vee = \left[ \a, \bAd_\X \b \right],
    \end{align}
  \end{subequations}
  whereas at $\X = \id$ they simplify to
  \begin{equation}
    \left( \mathrm{D} (\bAd_\X \b)_{\X = \id} \hat \a \right)^\vee = \mathrm{d}^r (\bAd_\X \b)_{\X = \id} \a= \mathrm{d}^l \left(\bAd_\X \b \right)_{\X = \id}  \a = \left[ \a, \b \right].
  \end{equation}
\end{properties}
The lower-case adjoint is defined as
\begin{equation}
  \label{eq:lowercase_adjoint}
  \begin{aligned}
    \ad_\a^0 \b & : = \b                                                                                                           \\
    \ad_\a^1 \b & : = \ad_\a \b = [\a,\b]                                                                                          \\
    \ad_\a^2 \b & : = [\a,  \ad_\a \b] = \underbrace{[\a,[\a,\b]]}_{2-\mathrm{times}}                                              \\
                & \vdots                                                                                                           \\
    \ad_\a^k \b & := [\a, \ad_\a^{k - 1} \b] = \underbrace{[\a, [ \a , \ldots, [\a,\b]]]}_{k \; \mathrm{times}} , \qquad k \geq 1.
  \end{aligned}
\end{equation}
From this definition it can be seen that for a scalar $s$,
\begin{equation}
  \label{eq:ad_scaling}
  \ad_{s \a}^k = s^k \ad_\a, \quad s \in \mathbb{R}
\end{equation}
If we formally define the exponential of the adjoint as
\begin{equation}
  \label{eq:def_expad}
  \exp \ad_\a \coloneq \sum_{k=0}^\infty \frac{\ad^k_\a}{k!}
\end{equation}
we can also show that the adjoint of the exponential equals the exponential of the adjoint.
\begin{properties}
  \begin{equation}
    \label{eq:adexp_expad}
    \bAd_{\exp \a} = \exp \ad_\a.
  \end{equation}
\end{properties}
\begin{proof}[Proof of \eqref{eq:adexp_expad}]
  By expanding the left-hand side in \eqref{eq:adexp_expad} and letting $\A = \hat \a, \B = \hat \b$ we obtain
  \begin{equation}
    \label{eq:exp_expansion}
    (\bAd_{\exp \a} \b)^\wedge = \Exp (\A) \B \Exp (-\A) = \sum_{k=0}^\infty \sum_{i = 0}^{k} \frac{\A^i \B (-\A)^{k-i}}{i! (k - i)!}.
  \end{equation}
  We next show by induction that the summands in \eqref{eq:exp_expansion} and \eqref{eq:def_expad} are equal for each value of $k$. Equality evidently holds for the base case $k=0$. Assume that it holds for $k-1$, i.e. that
  \begin{equation}
    \left( \frac{\ad_{\a}^{k-1} \b}{(k-1)!} \right)^\wedge = \sum_{i=0}^{k-1} \frac{\A^i \B (-\A)^{k-1-i}}{i! (k-1-i)!}.
  \end{equation}
  Then we have that
  \begin{equation*}
    \begin{aligned}
      \left( \frac{\ad_\a^{k} \b}{k!} \right)^\wedge = \frac{1}{k} \left[ \A \frac{(\ad_\A^{k-1} \B)}{(k-1)!} - \frac{(\ad_\A^{k-1} \B)}{(k-1)!} \A \right] =
      \frac{1}{k} \left[ \sum_{i=0}^{k-1} \frac{\A^{i+1} \B (-\A)^{k-1-i}}{i! (k-1-i)!} + \sum_{i=0}^{k-1} \frac{\A^i \B (-\A)^{k-i}}{i! (k-1-i)!} \right] \\
      = \frac{1}{k} \left[ \sum_{i=0}^{k-1} \frac{\A^i \B (-\A)^{k-i}}{i! (k-1-i)!} +  \sum_{i=1}^{k} \frac{\A^{i} \B (-\A)^{k-i}}{(i-1)! (k-i)!} \right] = \frac{\B (-\A)^k}{k!} + \sum_{i=1}^{k-1} c_i \A^i \B (-\A)^{k-i} + \frac{\A^k \B}{k!},
    \end{aligned}
  \end{equation*}
  where $c_i = \frac{1}{k} \left( \frac{1}{i!(k-1-i)!} + \frac{1}{(i-1)!(k-i)!} \right)$ and it can be verified that $c_i = \frac{1}{i!(k-i)!}$ as required.
\end{proof}
As a consequence,
\begin{equation}
  \label{eq:ad_exp_a_a}
  \bAd_{\lambda \exp(\a)} \a = \exp \ad_{\lambda \a} \a = \a. 
\end{equation}

Another useful identity is the following.
\begin{important}
  \begin{equation}
    \bAd_\X \left[ \a, \b \right] = \left[ \bAd_\X \a, \bAd_\X \b \right].
  \end{equation}
\end{important}
\section{Derivatives of the Exponential map}

The derivatives of the exponential map is a fundamental expression that often shows up when manipulating derivatives on Lie groups. From \eqref{eq:rght_deriv_traditional} we have that
\begin{equation}
  \mathrm{d}^r \exp_\a \b = \left( \exp(\bgamma(0))^{-1} \left. \frac{\mathrm{d}}{\mathrm{d}t}\right|_{t = 0} \exp(\bgamma(t)) \right)^\vee, \quad \bgamma(0) = \a, \; \bgamma'(0) = \b.
\end{equation}
To calculate this derivative consider a curve $\bgamma(t) \in \check{\mathfrak{m}}$ and the expression
\begin{equation}
  \label{eq:exponential_derivative_posit}
  \Gamma(\sigma, t) = \exp(\sigma \bgamma(t))^{-1} \frac{\partial}{\partial t}  \exp(\sigma \bgamma(t)) = \Exp \left( - \sigma \hat \bgamma(t) \right) \frac{\partial}{\partial t}  \Exp(\sigma \hat \bgamma(t)).
\end{equation}
Take the derivative with respect to $\sigma$:
\begin{equation}
  \begin{aligned}
    \frac{\partial}{\partial \sigma} \Gamma(\sigma, t)
     & = -\Exp \left(-\sigma \hat \bgamma(t) \right) \hat \bgamma(t) \frac{\partial}{\partial t} \Exp \left(\sigma \hat \bgamma(t) \right) + \Exp(-\sigma \hat \bgamma(t)) \frac{\partial}{ \partial t} \left[ \hat \bgamma(t) \Exp (\sigma \hat \bgamma(t)) \right]                             \\
     & = \Exp(-\sigma \hat \bgamma(t)) \hat \bgamma'(t) \Exp(\sigma \hat \bgamma(t)) = \Ad_{\Exp (- \sigma \hat \bgamma(t))}\hat \bgamma'(t) = \left(
    \bAd_{\exp(-\sigma \bgamma(t))} \bgamma'(t) \right)^\wedge                                                                                                                                                                                                                                   \\
     & \overset{\eqref{eq:adexp_expad}}= \left( \exp \ad_{-\sigma \bgamma(t)}\bgamma'(t) \right)^\wedge = \left( \sum_{k=0}^\infty \frac{\ad^k_{-\sigma \bgamma(t)}}{k!}\bgamma'(t) \right)^\wedge = \left( \sum_{k=0}^\infty \sigma^k \frac{\ad^k_{-\bgamma(t)}}{k!}\bgamma'(t) \right)^\wedge.
  \end{aligned}
\end{equation}
Integrating from 0 to 1 with respect to $\sigma$ and setting $t = 0$ then yields
\begin{equation}
  \Gamma(1, 0)^\vee = \int_0^1 \frac{\partial}{\partial \sigma} \Gamma(\sigma, 0)^\vee \mathrm{d} \sigma = \sum_{k=0}^\infty \frac{\ad^k_{-\bgamma(0)}}{(k+1)!}\bgamma'(0).
\end{equation}
From \eqref{eq:exponential_derivative_posit} we can see that $\Gamma(1, 0)$ is equal to the right derivative of $\exp$ at $\gamma(0)$ in the direction $\gamma'(0)$.

\begin{properties}
  The right- and left derivatives of the exponential map are
  \begin{equation}
    \label{eq:dexp_def}
    \begin{aligned}
      \mathrm{d}^r \exp_\a & = \frac{I - \exp (-\ad_{\a})}{\ad_{\a}} \coloneq \sum_{k=0}^\infty \frac{(-1)^k }{(k+1)!} \ad^k_{\a}, \\
      \mathrm{d}^l \exp_\a & = \frac{\exp \ad_{a} - I}{\ad_{a}} \coloneq \sum_{k=0}^\infty \frac{1 }{(k+1)!} \ad^k_{\a}.
    \end{aligned}
  \end{equation}
  Through the Bernoulli numbers $B_0 = 0, B_1 = -1/2, B_2 = 1/6, \ldots$ that are defined as
  \begin{equation}
    \label{eq:bernoulli_number_def}
    \frac{t}{e^t - 1} = \sum_{n=0}^\infty \frac{B_n}{n!} t^n.
  \end{equation}
  we can also write the formal inverses of the derivatives of the exponential
  \begin{equation}
    \label{eq:dexpinv_def}
    \begin{aligned}
      \left(\mathrm{d}^r \exp_\a\right)^{-1} & = \frac{\ad_{\a}}{I - \exp (- \ad_{\a})} \coloneq \sum_{n=0}^\infty B_n \frac{(-1)^n}{n!} \ad_{\a}^n, \\
      \left(\mathrm{d}^l \exp_\a\right)^{-1} & = \frac{\ad_{\a}}{\exp \ad_{\a} - I} \coloneq \sum_{n=0}^\infty B_n \frac{1}{n!} \ad_\a^n.
    \end{aligned}
  \end{equation}
  Notably, at $\a = \symbf{0}$ these are all equal to the identity matrix. Since $B_1 = -1/2$ and $B_n = 0$ for odd $n > 1$ it follows that
  \begin{equation}
    \left(\mathrm{d}^l \exp_\a\right)^{-1} = -\ad_\a + \left(\mathrm{d}^r \exp_\a\right)^{-1}.
  \end{equation}
\end{properties}
From these definitions it follows that
\begin{equation}
  \left[ \a, \b \right] = 0 \quad \implies \quad \mathrm{d}^r \exp_{\b} \a = \mathrm{d}^l \exp_\b = \left( \mathrm{d}^r \exp_\b \right)^{-1} = \left( \mathrm{d}^l \exp_\b \right)^{-1} = \a,
\end{equation}
which in particular holds for the case $\b = \lambda \a$.

While the derivatives \eqref{eq:dexp_def} - \eqref{eq:dexpinv_def} could be evaluated to arbitrary precision by adding enough terms, this is not a practical solution. Fortunately closed-form expressions can be obtained for all groups of interest, but we postpone those calculations to the next part.



\section{Derivatives of common operations}

\paragraph{Group composition}

We calculate the right derivatives using \eqref{eq:deriv_rght} and the left derivatives via \eqref{eq:derivative_trans}.

\begin{align}
  \label{eq:d_composition_rght_fst}
  \begin{split}
    \mathrm{d}^r (\X \circ \Y)_{\X}
    & \overset{\eqref{eq:deriv_rght}}= \lim_{\a \rightarrow 0} \frac{ \log \left( (\X \circ \Y)^{-1} \circ \X \circ \exp(\a) \circ \Y \right) }{\a} = \lim_{\a \rightarrow 0} \frac{ \log \left( \Y^{-1} \circ \exp(\a) \circ \Y \right) }{\a}                                                                                     \\
    & \overset{\eqref{eq:exp_adj_comm}}= \lim_{\a \rightarrow 0} \frac{\log \exp \bAd_{\Y^{-1}} \a}{\a} = \bAd_{\Y^{-1}},
  \end{split}
  \\
  \label{eq:d_composition_left_fst}
  \mathrm{d}^l (\X \circ \Y)_{\X}
   & \overset{\eqref{eq:derivative_trans}}= \bAd_{\X \circ \Y} \bAd_{\Y^{-1}} \bAd_{\X}^{-1} \overset{\eqref{eq:adjoint_properties}}= I_n,
  \\
  \label{eq:d_composition_rght_snd}
  \mathrm{d}^r (\X \circ \Y)_\Y
   & \overset{\eqref{eq:deriv_rght}}= \lim_{\a \rightarrow 0} \frac{ \log \left( (\X \circ \Y)^{-1} \circ \X \circ \Y \circ \exp(\a) \right) }{\a} = I_n,
  \\
  \label{eq:d_composition_left_snd}
  \mathrm{d}^l (\X \circ \Y)_{\Y}
   & \overset{\eqref{eq:derivative_trans}} = \bAd_{\X \circ \Y} I_n \bAd_{\Y}^{-1} \overset{\eqref{eq:adjoint_properties}}= \bAd_{\X}.
\end{align}

\paragraph{Group inverse}

\begin{align}
  \label{eq:d_inv_rght}
  \begin{split}
    \mathrm{d}^r (\X^{-1})_\X
    &\overset{\eqref{eq:deriv_rght}}= \lim_{\a \rightarrow 0} \frac{ \log \left( \X \circ (\X \circ \exp(\a))^{-1} \right) }{\a} =   \lim_{\a \rightarrow 0} \frac{ \log \left( \X \circ \exp(-\a) \circ \X^{-1} \right) }{\a}
    \\
    &
    \overset{\eqref{eq:exp_adj_comm}}= \frac{ \log \exp \bAd_\X -\a}{\a} = -\bAd_\X.
  \end{split}
  \\
  \label{eq:d_inv_left}
  \mathrm{d}^l (\X^{-1})_\X
   & \overset{\eqref{eq:derivative_trans}}= -\bAd_{\X^{-1}} \bAd_\X \bAd_{\X^{-1}} = -\bAd_{\X^{-1}}.
\end{align}

\paragraph{Logarithm}

From differentiating $\a = \log \exp \a$ using the chain rule we get $I = \mathrm{d}^r \log_{\exp \a} \; \mathrm{d}^r \exp_{\a}$, which implies that
\begin{align}
  \mathrm{d}^r \log_{\X} = \left[\mathrm{d}^r \exp_{\log \X} \right]^{-1}, \label{eq:d_log_rght} \\
  \mathrm{d}^l \log_{\X} = \left[\mathrm{d}^l \exp_{\log \X} \right]^{-1}. \label{eq:d_log_left} \\
\end{align}

\paragraph{Plus and minus}

From the chain rule and the above we can also deduce the derivatives of the plus and minus maps

\begin{align}
  \label{eq:d_rplus_fst}
  \mathrm{d}^r (\X \oplus_r \a)_\X  & = \mathrm{d}^r (\X \circ \exp (\a) )_\X \overset{\eqref{eq:d_composition_rght_fst}}= \bAd_{\exp(\a)}^{-1},
  \\
  \label{eq:d_rplus_snd}
  \mathrm{d}^r (\X \oplus_r \a)_\a  & = \mathrm{d}^r (\X \circ \exp (\a) )_\a \overset{\eqref{eq:chain_rule}}= \mathrm{d}^r (\X \circ \exp (\a) )_{\exp \a} \; \mathrm{d}^r \exp_\a \overset{\eqref{eq:d_composition_rght_snd}}= \mathrm{d}^r \exp_\a,
  \\
  \label{eq:d_rminus_fst}
  \mathrm{d}^r (\Y \ominus_r \X)_\Y & = \mathrm{d}^r \left(\log \X^{-1} \circ \Y \right)_\Y \overset{\eqref{eq:chain_rule}}= \mathrm{d}^r \log_{\X^{-1} \circ \Y} \; \mathrm{d}^r (\X^{-1} \circ \Y)_{\Y} \overset{\eqref{eq:d_composition_rght_snd}}= \left[ \mathrm{d}^r \exp_{\Y \ominus_r \X} \right]^{-1},
  \\
  \label{eq:d_rminus_snd}
  \begin{split}
    \mathrm{d}^r (\Y \ominus_r \X)_\X & = \mathrm{d}^r \left(\log \X^{-1} \circ \Y \right)_\X \overset{\eqref{eq:chain_rule}}= \mathrm{d}^r \log_{\X^{-1} \circ \Y} \; \mathrm{d}^r (\X^{-1} \circ \Y)_{\X^{-1}} \; \mathrm{d}^r (\X^{-1})_\X \\
    & \overset{\eqref{eq:d_log_rght}, \eqref{eq:d_composition_rght_fst}, \eqref{eq:d_inv_rght}}= \left[ \mathrm{d}^r \exp_{\Y \ominus_r \X} \right]^{-1} \bAd_{\Y^{-1}} (-\bAd_{\X}) \overset{\eqref{eq:ad_product}}= -\left[ \mathrm{d}^r \exp_{\Y \ominus_r \X} \right]^{-1} \bAd_{\Y^{-1} \circ \X} \\
    & = -\left[ \mathrm{d}^r \exp_{\Y \ominus_r \X} \right]^{-1} \bAd_{\exp \Y \ominus_r \X}^{-1} \overset{\eqref{eq:derivative_trans}}= - \left[ \mathrm{d}^l \exp_{\Y \ominus_r \X} \right]^{-1}.
  \end{split}
\end{align}

\section{On Automatic Differentiation}

Consider a function $f : \M \rightarrow \N$ whose derivative we are interested in. Since autodiff tools are not aware of manifolds we can not directly obtain e.g. $\mathrm{d}^r f_\X$; here we discuss how to obtain on-manifold derivatives by only differentiating Euclidean functions. Since $\mathrm{d}^r (f(\X \oplus_r \a))_{\a = 0} = \mathrm{d}^r f_\X \mathrm{d} \exp_0 = \mathrm{d}^r f_\X$ we can write
\begin{equation}
  \begin{aligned}
    \mathrm{d}^r f_\X \b = \mathrm{d}^r (f(\X \oplus_r \a))_{\a = 0} \b = \left.  \left( f(\X \oplus_r \a)^{-1} \mathrm{D} (f(\X \oplus_r \a))_\a \hat \b  \right)^\vee \right|_{\a = 0} = \left( f(\X)^{-1}  \left. \frac{\mathrm{d}}{\mathrm{d}t} \right|_{t=0}  f(\X \oplus (t \b)) \right)^\vee.
  \end{aligned}
\end{equation}
Here the function $t \mapsto f(\X \oplus (t\b))$ maps a scalar to a matrix and can therefore be differentiated using regular tools, after which the expression can be evaluated to obtain $\mathrm{d}^r f_\X \b$. Naturally, if the complete derivative $\mathrm{d}^r f_\X$ is desired it can be obtained by repeating this procedure $n$ times for each basis unit vector.

If $f$ maps to a Euclidean space (i.e. $\N = \mathbb{R}^k$) this further simplifies to
\begin{equation}
  \mathrm{d}^r f_\X b = \left. \frac{\mathrm{d}}{\mathrm{d}t} \right|_{t=0} f(\X \oplus (t \b)), \quad f : \M \rightarrow \mathbb{R}^n,
\end{equation}
which with some abuse of notation can be written as
\begin{equation}
  \label{eq:rn_autodiff}
  \mathrm{d}^r f_\X = \left. \frac{\mathrm{d}}{\mathrm{d}\b} \right|_{\b = 0} f(\X \oplus \b).
\end{equation}

\todo[inline]{Pretty sure this will immediately yield the correct derivative}
\begin{equation}
  \left. \frac{\mathrm{d}}{\mathrm{d}\b} \right|_{\b = 0} \log \left( f(\X)^{-1} f(\X \oplus \b) \right)
\end{equation}

\subsection{Ceres Solver Local Parameterizations}

A special case of when numerical derivatives are used is in the nonlinear optimizer Ceres. Being unaware of Lie groups, Ceres considers cost functions that are functions of some parameters, $f(\x)$, and uses automatic differentiation of $f : \mathbb{R}^p \rightarrow \mathbb{R}^k$ with respect to $\x \in \mathbb{R}^p$ to figure out in what direction to move in order to minimize $f$. However, if $\x$ represents the coordinates of a manifold chart, i.e. $\hat \x = \X$ for $\X \in \M$, it is not desirable to directly apply an update in the direction of the gradient since this may lead the resulting point no longer being on the manifold.

Being unaware of the manifold structure, automatic differentiation can only evaluate $\frac{\mathrm{d}}{\mathrm{d}\x} f(\hat \x)$, where we are using the hat and vee maps to denote conversions between elements of a Lie group $\M$ and its parameterization $\cM$ as was done in Chapter \ref{chapter:lie_groups}. Ceres provides an interface for specifying cusom \emph{local parameterizations} that enable on-manifold optimization. In the following we specify how a local parameterization for Lie Group optimization can be constructed.

According to \eqref{eq:rn_autodiff} we can write a tangent space derivative for a Euclidean-valued function
\begin{equation}
  \mathrm{d}^r f_\X = \left. \frac{\mathrm{d}}{\mathrm{d}\b} \right|_{\b = 0} f(\X \oplus \b) = \left. \frac{\mathrm{d}}{\mathrm{d}\b} \right|_{\b = 0} f \left( \left( \left( \hat \x \oplus \b \right)^\vee \right)^\wedge \right) = \left. \frac{\mathrm{d}}{\mathrm{d} \y} \right|_{\y = \x} f(\hat \y) \; \times \; \left. \frac{\mathrm{d}}{\mathrm{d} \b} \right|_{\b = 0} \left( \hat \x \oplus \b\right)^\vee.
\end{equation}

Thus, if $\left. \frac{\mathrm{d}}{\mathrm{d} \y} \right|_{\y = \x} f(\hat \y)$ is obtained through automatic differentiation it needs to be right-multiplied by a state-dependent matrix in order to obtain the tangent-space derivative. In Ceres parlance these matrices are called
\begin{itemize}
  \item Local derivative: $\mathrm{d}^r f_\X$, a $k \times n$ matrix,
  \item Global derivative: $\left. \frac{\mathrm{d}}{\mathrm{d} \y} \right|_{\y = \x} f(\hat \y)$, a $k \times p$ matrix,
  \item Jacobian: $\left. \frac{\mathrm{d}}{\mathrm{d} \b} \right|_{\b = 0} \left( \hat \x \oplus \b\right)^\vee$, a $p \times n$ matrix
\end{itemize}
and it holds that (local derivative) = (global derivative) $\times$ (jacobian). The local parameterization for a Lie group can be specified as follows:
\begin{itemize}
  \item Plus operation: $\x \boxplus \b \coloneq \left( \hat \x \oplus \b \right)^\vee$,
  \item Local dimension: $n = \| T \M \|$ tangent space dimension,
  \item Global dimension: $p = \| \cM \|$ group parameterization dimension,
  \item Jacobian: $\left. \frac{\mathrm{d}}{\mathrm{d} \b} \right|_{\b = 0} \left( \hat \x \oplus \b\right)^\vee$.
\end{itemize}

