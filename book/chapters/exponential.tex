% !TEX root = ../manuscript.tex

\chapter{The Exponential Map}

\begin{itemize_outcomes}
  \item The Exponential map and how it connects a Lie group to its Lie algebra.
  \item The Lie group logarithm,  plus and minus operators.
  \item The structure of the Lie algebras corresponding to common Lie groups.
\end{itemize_outcomes}

\todo[inline]{Need a nice derivation showing how lie algebra properties arise}

\section{One-Parameter Groups}

\textbf{Best way to prove that Lie Groups have Lie Algebras?}
\begin{itemize}
  \item In \cite{howe_very_1983} it is shown that for \textbf{matrix} Lie groups the set $\{ A \in \textrm{End} V : \exp tA \in G \forall t \} = \cap_{t} t \exp^{-1}(G)$ is a Lie Algebra (i.e. closed under the bracket operation).
\end{itemize}

Dual viewpoint: solutions $\Phi(x, t)$ of ODEs correspond to one-parameter groups \cite{howe_very_1983}.

Connection to linear systems.

\section{The Exponential Map}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[
        setnode/.style = {
            draw,
            circle,
            minimum width=1.2cm
          },
        node distance=4em
      ]
      \node[setnode] (group) {$\M$};
      \node[setnode, below=of group, xshift=18mm] (algebra_param) {$\clM$};
      \node[setnode, below=of group, xshift=-18mm] (algebra) {$\lM$};

      \draw[-latex] (algebra) to node[above] {$\vee$} (algebra_param);
      \draw[-latex] (algebra_param) to[bend left] node[above] {$\wedge$} (algebra);

      \draw[-latex] (algebra) to[bend left] node[left] {$\Exp$} (group);
      \draw[-latex] (algebra_param) to[bend right] node[right] {$\exp$} (group);

      \draw[-latex] (group) to[bend left] node[left] {$\Log$} (algebra);
      \draw[-latex] (group) to[bend right] node[right] {$\log$} (algebra_param);
    \end{tikzpicture}
  \end{center}
  \caption{Illustration of how the exponential maps connect a Lie Group $\M$, its Lie Algebra $\lM$, and the Lie Algebra parameterization which is the linear space $\clM \cong \mathbb{R}^n$.}
  \label{fig:exponentials}
\end{figure}


\begin{definition}
  \label{def:exponential}
  The \textbf{Exponential map} of a matrix $\A \in \mathbb{C}^{n \times n}$ and $t \in \mathbb{R}$ is
  \begin{equation}
    \Exp(\A) = \sum_{n = 0}^\infty \frac{\A^n}{n!} \in \mathbb{C}^{n \times n}.
  \end{equation}
\end{definition}

\begin{properties}[title=Properties of the exponential map]
  For the exponential map in Definition \ref{def:exponential} we have
  \begin{subequations}
    \begin{align}
      \Exp(t \A) \Exp (s \A)                    & = \Exp((t+s) \A), \label{eq:exp_composition} \\
      \frac{\mathrm{d}}{\mathrm{d}t} \Exp(t \A) & = \A \Exp(t \A) = \Exp(t \A) \A,             \\
      \det (\Exp (\A))                          & = e^{\tr (\A)}. \label{eq:jacobi_identity}
    \end{align}
  \end{subequations}
\end{properties}
The first two follow directly from the definition and are analogous to the scalar exponential map. Furthermore, \eqref{eq:exp_composition} implies that $\{ \Exp(t \A) : t \in \mathbb{R} \}$ is a one-parameter subgroup of $\M$.

Not however that in general $\exp(\A + \B) \neq \exp (\A) \circ \exp(\B)$ which is different from the scalar version. Equation \eqref{eq:jacobi_identity}, known as Jacobi's identity, motivates a short proof:
\begin{proof}[Proof of \eqref{eq:jacobi_identity}]
  It is easy to see that the eigenvalues of $\Exp(\A)$ are the exponentials of the eigenvalues of $\A$. Since the determinant equals the product of the eigenvalues it follows that
  \begin{equation}
    \det (\Exp \A) = \prod_{i=1}^n \lambda_i(\Exp \A) = \prod_{i=1}^n e^{\lambda_i(\A)} = e^{\sum_{i=1}^n \lambda_i(\A)} = e^{\tr(\A)}.
  \end{equation}
\end{proof}

\subsection{Modern Definition}

We contrast the algebraic Definition \ref{def:exponential} with a more modern definition usually found in texts on differential geometry.

\begin{definition}
  The \textbf{exponential} of $\A \in \lM$ is
  \begin{equation}
    \Exp \A \coloneq \gamma(1),
  \end{equation}
  where $\gamma$ is a one-parameter subgroup of $\M$ such that $\gamma'(0) = \A$.
\end{definition}
This definition of course works even in the case that $\M$ is not a matrix Lie group, in fact it the same definition is used in more general differential geometry. We show that it coincides with Definition \ref{def:exponential} for matrix Lie groups.

\begin{proof}
  We know that $\gamma(0) = I$, $\gamma'(0) = \A$, and $\gamma(s) \gamma(t) = \gamma(s + t)$ by virtue of $\gamma$ being a one-parameter sub-group.
  \begin{equation}
    \left( \gamma\left( \frac{h}{2} \right) - \gamma \left( -\frac{h}{2} \right)\right)^n = \sum_{k=0}^n (-1)^{k} \binom{n}{k} \gamma\left( \frac{h}{2} \right)^{n-k} \gamma\left(-\frac{h}{2} \right)^{k} = \sum_{k = 0}^n (-1)^{k} \binom{n}{k} \gamma\left( \left( \frac{n}{2} - k \right)  h  \right).
  \end{equation}
  For $h \rightarrow 0$ the left-hand side goes to $ \left( h \gamma'(0) \right)^n$, whereas the right-hand side is a finite-difference approximation of $h^n \gamma^{(n)}(0)$. It follows that $\gamma^{n}(0) = \A^n$, and hence a Taylor expansion around $0$ gives
  \begin{equation}
    \gamma(1) = \sum_{k \geq 0} \frac{\gamma^{(n)}(0) (1 - 0)^n}{n!} = \sum_{k \geq 0} \frac{\A^n}{n!}.
  \end{equation}
\end{proof}
A consequence of the proof above is that one-parameter subgroups of Lie groups are uniquely defined by their derivative at zero, and are therefore analogous to geodesics in Riemannian geometry.


\section{The Lie Algebra of a Lie group}

\begin{definition}
  For a matrix Lie group $\M$ the corresponding \textbf{matrix Lie algebra} $\lM$ is
  \begin{equation}
    \lM = \{ \A : \Exp(t \A) \in \mathbb{M} \; \forall t \in \mathbb{R} \}.
  \end{equation}
\end{definition}
Just as for Lie groups, the matrix Lie algebras are typically parameterized by fewer than $n^2$ coefficients. In order to work with efficient parameterizations we therefore introduce a lower-dimensional parameterization denoted $\clM$. For this lower-dimensional representation we also define a lowercase exponential that maps from the parameterized lie algebra representation $\clM$ to the parameterized group representation $\cM$:
\begin{equation}
  \exp (\a) = \Exp(\a^{\wedge}).
\end{equation}
The relationshop between the exponential maps and the hat and vee maps is shown in Figure \ref{fig:exponentials}.

\todo[inline]{Show that Lie algebra defined like this is indeed a Lie algebra(closed under bracket, jacobi, etc). Use property from previous chapter to show that as $t \rightarrow 0$ we obtain a tangent that is equal to the bracket. Group property is then enough to conclude.}

\section{The Logarithm}

The matrix logarithm $\Log : \mathbb{M} \rightarrow \mathfrak{m}$ is defined as the inverse of the matrix exponential, and we also define lowercase $\log : \M \rightarrow \clM$ for mappings between the parameterized representations:
\begin{equation}
  \begin{aligned}
    \Log \X & = \sum_{k \geq 1} (-1)^{k+1} \frac{(\X - I)^k}{k}, \\
    \log \X & = \left( \Log \X \right)^{\vee}.
  \end{aligned}
\end{equation}

\todo[inline]{Show that it's the inverse of the exponential}

\section{Baker–Campbell–Hausdorff formula}

\todo[inline]{Prove BCH formula and provide context}

\begin{equation}
  \label{eq:bch_formula}
  \log \left(\exp \a \circ \exp \b \right) = \a + \b + \frac{1}{2} \left[ \a, \b \right] + \frac{1}{12} \left[ \a, \left[ \a, \b \right]\right] - \frac{1}{12} \left[ \b, \left[ \a, \b \right]\right] + \ldots
\end{equation}

\section{Plus and Minus Operators}

Algorithms for optimization and numerical integration require taking small additative steps, but Lie groups are not closed under normal addition and subtraction. We can however define generalized addition and subtraction operators $\oplus, \ominus$ for Lie groups that behave similarly to how $+$ and $-$ operate on regular vector spaces.


\begin{important}%
  The plus operations add an increment $\a \in \clM$ in the parameterized tangent space to an element $\X \in \M$ of the group, whereas the minus operators give the difference between two group elements as a vector in the parameterized tangent space.
  \begin{align}
    \label{eq:right-plus}
    \tag{right-plus} \X \oplus_r {{\a}}
     & = \X \circ \exp \left( {{\a}} \right) \in \cM,                     \\
    \label{eq:right-minus}
    \tag{right-minus}\Y \ominus_r \X
     & =  \log \left( \X^{-1} \circ \Y \right) \in T_{\X} \cM \cong \clM, \\
    \label{eq:left-plus}
    \tag{left-plus} \a \oplus_l \X
     & = \exp \left( {{\a}} \right) \circ \X \in \cM,                     \\
    \label{eq:left-minus}
    \tag{left-minus}\Y \ominus_l \X
     & =  \log \left( \Y \circ \X^{-1} \right) \in T_\id \cM \cong \clM .
  \end{align}
\end{important}
The plus operators are differentiated by the order: the right-plus has the tangent element at $\X$ while left-plus has the reverse order, meaning that the tangent element belongs to the tangent space at $\id$.

Note that the derivates are defined in a way so that
\begin{subequations}
  \begin{align}
    \X \oplus_r (\Y \ominus_r \X ) & = \X \circ \exp \log (\X^{-1} \Y) = \Y,                                     \\
    (\X \oplus_r \a) \ominus_r \X  & = \log (\X^{-1} \circ \X \circ \exp \a) = \a,   \label{eq:x_plus_a_minus_x} \\
    (\Y \ominus_l \X ) \oplus_l \X & = \exp \log (\Y \circ \X^{-1}) \circ \X = \Y,                               \\
    (\a \oplus_l \X) \ominus_l \X  & = \log (\exp \a \circ \X \circ \X^{-1}) = \a.
  \end{align}
\end{subequations}


\section{Homomorphy of Lie Groups implies Homomorphy of Lie Algebras}

This is important since it implies that $SO(3)$ and $S^3$ can be treated analogously. A proof is in \cite[Corr. 20]{howe_very_1983}.

\section{The Adjoint}

We define the \textbf{adjoint} $\Ad_\X : \lM \rightarrow \lM$ of a matrix $\A \in \lM$ as
\begin{equation}
  \Ad_{\X} \A \coloneq \X \A \X^{-1}.
\end{equation}
From the definition of the exponential map in \eqref{def:exponential} it can be seen that $\Exp( \Ad_\X \A) \in \M$ if and only if $\Exp (\A) \in \M$, which implies that the lie algebra $\lM$ is closed under action of the adjoint.

The adjoint of a tangent matrix element $\a \in \clM$ is similary defined as a linear mapping $\bAd_\X : \clM \rightarrow \clM$:
\begin{equation}
  \label{eq:def_bad}
  \bAd_\X \a \coloneq (\Ad_{\X} \hat \a)^\vee = (\X \hat \a \X^{-1})^\vee.
\end{equation}
For a given $\X$ this is a linear map, so $\bAd_\X$ is an $n \times n$ matrix. The adjoint represents a coordinate change from the tangent space $T_\X \cM$ to the tangent space $\T_\id \cM = \clM$ at the origin.

\begin{remark}
  Since the definition of $\Ad$ involves matrix multiplication it does not make sense for groups like $\check{\SOtwo}$ and $\Sthree$ that are not matrix Lie groups. We can however still define the bold-face adjoint $\bAd$ on $\cM$ as
  \begin{equation}
    \bAd_{\x} \coloneq \bAd_{\hat \x},
  \end{equation}
  where $\wedge : \cM \rightarrow \M$ is a Lie group homomorphism that maps $\cM$ into a matrix Lie group.
\end{remark}

\begin{properties}[title=Properties of the adjoint]
  The adjoints satisfy the following properties:
  \begin{subequations}
    \label{eq:adjoint_properties}
    \begin{align}
      \bAd_\X^{-1}          & = \bAd_{\X^{-1}},                                                    \\
      \bAd_\X \bAd_\Y       & = \bAd_{\X \circ \Y},              \label{eq:ad_product}             \\
      \exp \; \bAd_\X \; \a & =  \X \circ \exp \a \circ \X^{-1},           \label{eq:exp_adj_comm} \\
      \X \oplus_r \a        & = (\bAd_\X \a) \oplus_l \X.  \label{eq:plus_adjoint}
    \end{align}
  \end{subequations}
\end{properties}

The first two properties follow directly from the definition. Equation \eqref{eq:exp_adj_comm} follows from
\begin{equation}
  \begin{aligned}
    \exp \bAd_\X \a = \Exp \; \Ad_X \; \hat \a =  \sum_{k \geq 0} \frac{\left( \X \hat \a \X^{-1} \right)^k}{k} = \X \left( \sum_{k \geq 0} \frac{ \hat \a ^k}{k} \right) \X^{-1} =  \X \exp (\a) \X^{-1}.
  \end{aligned}
\end{equation}
We can then also show \eqref{eq:plus_adjoint}
\begin{equation}
  \X \oplus_r \a \overset{\eqref{eq:right-plus}}= \X \circ \exp (\a) = (\X \circ \exp (\a) \circ \X^{-1}) \circ \X \overset{\eqref{eq:exp_adj_comm}}= \exp (\bAd_\X \a) \circ \X \overset{\eqref{eq:left-plus}}= (\bAd_\X \a) \oplus_l \X.
\end{equation}

Finally a result regarding the derivative of the adjoint.

\begin{lemma}
  \label{lem:d_bad_exp}
  \begin{equation}
    \frac{\mathrm{d}}{\mathrm{d}t} \bAd_{\exp(\lambda(t) \a)} = \lambda'(t) \ad_{\a} \bAd_{\exp(\lambda(t) \a)}.
  \end{equation}
\end{lemma}
\begin{proof}
  \begin{equation}
    \begin{aligned}
      \frac{\mathrm{d}}{\mathrm{d}t} \bAd_{\exp(\lambda(t) \a)}
      \overset{\eqref{eq:adexp_expad}}= \frac{\mathrm{d}}{\mathrm{d}t} \sum_{k = 0}^\infty \exp(\ad_{\lambda(t) \a})
      \overset{\eqref{eq:ad_{scaling}}}= \frac{\mathrm{d}}{\mathrm{d}t} \sum_{k = 0}^\infty \exp(\lambda(t) \ad_{\a})
      \overset{\eqref{eq:def_expad}}= \frac{\mathrm{d}}{\mathrm{d}t} \sum_{k=0}^{\infty} \frac{\lambda(t)^{k} \ad_{\a}^{k}}{k!} \\
      = \lambda'(t) \sum_{k=1}^{\infty} \frac{\lambda(t)^{k-1} \ad_{\a}^{k}}{(k-1)!} = \lambda'(t) \ad_{\a} \sum_{k=1}^{\infty} \frac{\lambda(t)^{k-1} \ad_{\a}^{k-1}}{(k-1)!} = \lambda'(t) \ad_{\a} \bAd_{\exp(\lambda(t) \a)}.
    \end{aligned}
  \end{equation}
\end{proof}
